spring:
  application:
    name: spring-ai-ollama
  http:
    client:
      factory: jdk  # 必须显式设置，否则默认 reactor，会影响特定的 AI workflows, 例如: ImageModel
  ai:
    model:
      chat: ollama
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.2:3b # phi3:mini
          temperature: 0.7
logging:
  level:
    org.springframework.ai.chat.client.advisor: debug
